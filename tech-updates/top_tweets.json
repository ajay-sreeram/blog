[{"url": "https://twitter.com/jmin__cho/status/1715082945265053782?s=12", "code": "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">\ud83c\udfa8DiagrammerGPT: a novel 2-stage text-to-diagram generation framework leveraging LLMs (e.g., GPT-4) to create fine-grained layouts for open-domain, open-platform diagrams (w/ dense objects+complex relations)!<a href=\"https://t.co/oJk7yYEUOU\">https://t.co/oJk7yYEUOU</a><a href=\"https://twitter.com/AbhayZala7?ref_src=twsrc%5Etfw\">@AbhayZala7</a> <a href=\"https://twitter.com/hanlin_hl?ref_src=twsrc%5Etfw\">@hanlin_hl</a> <a href=\"https://twitter.com/mohitban47?ref_src=twsrc%5Etfw\">@mohitban47</a> <a href=\"https://twitter.com/uncnlp?ref_src=twsrc%5Etfw\">@uncnlp</a><br>\ud83e\uddf5 <a href=\"https://t.co/1lSJBGgm9k\">https://t.co/1lSJBGgm9k</a> <a href=\"https://t.co/aTWy9oMaNn\">pic.twitter.com/aTWy9oMaNn</a></p>&mdash; Jaemin Cho (@jmin__cho) <a href=\"https://twitter.com/jmin__cho/status/1715082945265053782?ref_src=twsrc%5Etfw\">October 19, 2023</a></blockquote>"}, {"url": "https://twitter.com/_akhaliq/status/1715237306506813678?s=12", "code": "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">AutoMix: Automatically Mixing Language Models<br><br>paper page: <a href=\"https://t.co/Mz04TCOlH8\">https://t.co/Mz04TCOlH8</a><br><br>Large language models (LLMs) are now available in various sizes and configurations from cloud API providers. While this diversity offers a broad spectrum of choices, effectively leveraging the\u2026 <a href=\"https://t.co/geo4sXLnhE\">pic.twitter.com/geo4sXLnhE</a></p>&mdash; AK (@_akhaliq) <a href=\"https://twitter.com/_akhaliq/status/1715237306506813678?ref_src=twsrc%5Etfw\">October 20, 2023</a></blockquote>"}, {"url": "https://twitter.com/haihaoshen/status/1715335763032780853?s=12", "code": "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">\ud83d\udce2StreamingLLM landed in Intel Extension for Transformers to support LLM inference infinity on CPU, up to 4M tokens! <br>\ud83c\udfafCheck out the code: <a href=\"https://t.co/oWYnKP6OQt\">https://t.co/oWYnKP6OQt</a>, search &quot;StreamingLLM&quot; and have a try!<a href=\"https://twitter.com/hashtag/oneapi?src=hash&amp;ref_src=twsrc%5Etfw\">#oneapi</a> <a href=\"https://twitter.com/intel?ref_src=twsrc%5Etfw\">@intel</a> <a href=\"https://twitter.com/huggingface?ref_src=twsrc%5Etfw\">@huggingface</a> <a href=\"https://twitter.com/Guangxuan_Xiao?ref_src=twsrc%5Etfw\">@Guangxuan_Xiao</a> <a href=\"https://twitter.com/_akhaliq?ref_src=twsrc%5Etfw\">@_akhaliq</a></p>&mdash; Haihao Shen (@HaihaoShen) <a href=\"https://twitter.com/HaihaoShen/status/1715335763032780853?ref_src=twsrc%5Etfw\">October 20, 2023</a></blockquote>"}, {"url": "https://twitter.com/_philschmid/status/1715056650351194477?s=12", "code": "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Can we pre-train LLMs with Retrieval Augmentation? \ud83e\udd14 RETRO was a research by <a href=\"https://twitter.com/GoogleDeepMind?ref_src=twsrc%5Etfw\">@GoogleDeepMind</a>, which included retrieval into the pre-trainng process. Now <a href=\"https://twitter.com/nvidia?ref_src=twsrc%5Etfw\">@NVIDIA</a> continues this research by scaling RETRO to 48B\ud83e\udd2f<br><br>\ud83e\uddf6 <a href=\"https://t.co/5iQqSzdfgn\">pic.twitter.com/5iQqSzdfgn</a></p>&mdash; Philipp Schmid (@_philschmid) <a href=\"https://twitter.com/_philschmid/status/1715056650351194477?ref_src=twsrc%5Etfw\">October 19, 2023</a></blockquote>"}, {"url": "https://twitter.com/matchaman11/status/1715023613982601497?s=12", "code": "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">What if you can use Github Copilot locally \ud83e\udd2f<br><br>Introducing LocalPilot<br><br>Open-source alternative to Github Copilot<br><br>Generate code locally integrated with VS Code<br><br>Currently trending on Github and Hackernews \u26a1\ufe0f<br><br>Link to project below \ud83d\udc47 <a href=\"https://t.co/OpsWqkgBZi\">pic.twitter.com/OpsWqkgBZi</a></p>&mdash; Anil Chandra Naidu Matcha (@matchaman11) <a href=\"https://twitter.com/matchaman11/status/1715023613982601497?ref_src=twsrc%5Etfw\">October 19, 2023</a></blockquote>"}]