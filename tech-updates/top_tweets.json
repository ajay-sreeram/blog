[{"url": "https://twitter.com/simontwice2/status/1717532965247529365?s=12", "code": "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">\u2728 Introducing \ud83c\udf79 Mixture of Tokens \ud83c\udf79, a stable alternative to existing Mixture of Experts techniques for LLMs, providing significantly more stable training \ud83d\udcc8. You can check out our initial results at <a href=\"https://t.co/D5ldj6v2uI\">https://t.co/D5ldj6v2uI</a> \ud83e\uddf5 (1/n) <a href=\"https://t.co/aJjWATeahE\">pic.twitter.com/aJjWATeahE</a></p>&mdash; Szymon Antoniak (@Simontwice2) <a href=\"https://twitter.com/Simontwice2/status/1717532965247529365?ref_src=twsrc%5Etfw\">October 26, 2023</a></blockquote>"}, {"url": "https://twitter.com/_akhaliq/status/1716308854428860662?s=12", "code": "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">DreamSpace: Dreaming Your Room Space with Text-Driven Panoramic Texture Propagation<br><br>paper page: <a href=\"https://t.co/a2YzIG8jNG\">https://t.co/a2YzIG8jNG</a><br><br>Diffusion-based methods have achieved prominent success in generating 2D media. However, accomplishing similar proficiencies for scene-level mesh texturing in\u2026 <a href=\"https://t.co/AVrrselTq0\">pic.twitter.com/AVrrselTq0</a></p>&mdash; AK (@_akhaliq) <a href=\"https://twitter.com/_akhaliq/status/1716308854428860662?ref_src=twsrc%5Etfw\">October 23, 2023</a></blockquote>"}, {"url": "https://twitter.com/ai2_aristo/status/1715482682854101017?s=12", "code": "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Can LLMs simulate human behavior in complex environments? How do we even test this? We release a simulation environment called AucArena for evaluating LLMs within English auctions, a setting involving many skills related to resource and risk management. <a href=\"https://t.co/4paBDCxxJk\">https://t.co/4paBDCxxJk</a> <a href=\"https://t.co/qi2sSTCldx\">https://t.co/qi2sSTCldx</a></p>&mdash; Aristo Team at AI2 (@ai2_aristo) <a href=\"https://twitter.com/ai2_aristo/status/1715482682854101017?ref_src=twsrc%5Etfw\">October 20, 2023</a></blockquote>"}, {"url": "https://twitter.com/langchainai/status/1715393748581109888?s=12", "code": "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">\u2b50\ufe0f Multi-Vector Retriever for RAG on tables, text, and images \u2b50\ufe0f<br><br>Seamless question-answering across diverse data types (images, text, tables) is one of the holy grails of RAG.<br><br>We\u2019re releasing three new cookbooks that showcase the multi-vector retriever to tackle this challenge.\u2026 <a href=\"https://t.co/T9nkDSWp4P\">pic.twitter.com/T9nkDSWp4P</a></p>&mdash; LangChain (@LangChainAI) <a href=\"https://twitter.com/LangChainAI/status/1715393748581109888?ref_src=twsrc%5Etfw\">October 20, 2023</a></blockquote>"}, {"url": "https://twitter.com/jmin__cho/status/1715082945265053782?s=12", "code": "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">\ud83c\udfa8DiagrammerGPT: a novel 2-stage text-to-diagram generation framework leveraging LLMs (e.g., GPT-4) to create fine-grained layouts for open-domain, open-platform diagrams (w/ dense objects+complex relations)!<a href=\"https://t.co/oJk7yYEUOU\">https://t.co/oJk7yYEUOU</a><a href=\"https://twitter.com/AbhayZala7?ref_src=twsrc%5Etfw\">@AbhayZala7</a> <a href=\"https://twitter.com/hanlin_hl?ref_src=twsrc%5Etfw\">@hanlin_hl</a> <a href=\"https://twitter.com/mohitban47?ref_src=twsrc%5Etfw\">@mohitban47</a> <a href=\"https://twitter.com/uncnlp?ref_src=twsrc%5Etfw\">@uncnlp</a><br>\ud83e\uddf5 <a href=\"https://t.co/1lSJBGgm9k\">https://t.co/1lSJBGgm9k</a> <a href=\"https://t.co/aTWy9oMaNn\">pic.twitter.com/aTWy9oMaNn</a></p>&mdash; Jaemin Cho (@jmin__cho) <a href=\"https://twitter.com/jmin__cho/status/1715082945265053782?ref_src=twsrc%5Etfw\">October 19, 2023</a></blockquote>"}]